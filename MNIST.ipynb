{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2dc43b5",
   "metadata": {},
   "source": [
    "# MNIST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a33fc6",
   "metadata": {},
   "source": [
    "In this project we will be using The MNISt dataset, which is a set of 70,000 small images of digits handwritten by high  school  students  and  employees  of  the  US  Cen‐sus Bureau. Each image is labeled with the digit it represents. This set has been stud‐ied  so  much  that  it  is  often  called  the  “hello  world”  of  Machine  Learning.\n",
    "</br>\n",
    "Scikit-Learn provides many helper functions to download popular datasets. MNIST isone of them. The following code fetches the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcfe1619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6762d476",
   "metadata": {},
   "source": [
    "Datasets loaded by Scikit-Learn generally have a similar dictionary structure, includ‐ing the following:\n",
    "- A DESCR key describing the dataset\n",
    "- A  data  key  containing  an  array  with  one  row  per  instance  and  one  column  perfeature\n",
    "- A target key containing an array with the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2b84ec41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "\n",
    "# this is different from the book (due to version mismatch of sklearn)\n",
    "# The dataframe has to be changed to numpy array for further calculation\n",
    "X = X.to_numpy() \n",
    "y = y.to_numpy()\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894e118f",
   "metadata": {},
   "source": [
    "There are 70,000 images, and each image has 784 features. This is because each imageis  28  ×  28  pixels,  and  each  feature  simply  represents  one  pixel’s  intensity,  from  0 (white) to 255 (black). Let’s take a peek at one digit from the dataset. All we need to do  is  grab  an  instance’s  feature  vector,  reshape  it  to  a  28  ×  28  array,  and  display  it using Matplotlib’s *imshow()* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "66d612fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "some_digit = X[0]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "\n",
    "plt.imshow(some_digit_image, cmap=\"binary\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df00d459",
   "metadata": {},
   "source": [
    "The y label is string, lets change it to integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e83723a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f903f943",
   "metadata": {},
   "source": [
    "The MNIST dataset is actually already split into a training set (the first 60,000images) and a test set (the last 10,000 images).\n",
    "</br>\n",
    "The training set is already shuffled for us, which is good because this guarantees that all cross-validation folds will be similar (we don’t want one fold to be missing some digits). Moreover, some learning algorithms are sensitive to the order of the training instances, and they perform poorly if they get many similar instances in a row. Shuffling the dataset ensures that this won’t happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c7311e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762e7168",
   "metadata": {},
   "source": [
    "## Training a Binary Classifier\n",
    "\n",
    "Let’s  simplify  the  problem  for  now  and  only  try  to  identify  one  digit for  example, the  number  5.  This  “5-detector”  will  be  an  example  of  a  binary  classifier,  capable  of distinguishing between just two classes, 5 and not-5. Let’s create the target vectors for this classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8ca3d7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_5 = (y_train == 5) # True for all 5s, False for all other digits\n",
    "y_test_5 = (y_test == 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ad1d00",
   "metadata": {},
   "source": [
    "Now let’s pick a classifier and train it. A good place to start is with a Stochastic Gradient  Descent  (SGD)  classifier,  using  Scikit-Learn’s  SGDClassifier  class.  This  classifier has  the  advantage  of  being  capable  of  handling  very  large  datasets  efficiently.  This  is in  part  because  SGD  deals  with  training  instances  independently,  one  at  a  time (which also makes SGD well suited for online learning), as we will see later. Let’s create an SGDClassifier and train it on the whole training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e129980b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(random_state=42)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79b48f0",
   "metadata": {},
   "source": [
    "Now we can use it to detect images of the number 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "16b96986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22295e5",
   "metadata": {},
   "source": [
    "The prediction was indeed right as we have used *some_digit* which is variable with value 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1426e36b",
   "metadata": {},
   "source": [
    "## Performance Measures\n",
    "\n",
    "Evaluating a classifier is often significantly trickier than evaluating a regressor, so we will  spend  a  large  part  of  this  chapter  on  this  topic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9998d6",
   "metadata": {},
   "source": [
    "### Measuring Accuracy Using Cross-Validation\n",
    "\n",
    "Occasionally we will need more control over the cross-validation process than what Scikit-Learn provides off the shelf. In these cases, we can implement cross-validation ourself. The   following   code   does   roughly   the   same   thing   as   Scikit-Learns *cross_val_score()* function, and it prints the same result.\n",
    "</br>\n",
    "The  *StratifiedKFold*  class  performs  stratified  sampling  (as  explained  in  Chapter  2) to produce folds that contain a representative ratio of each class. At each iteration the code creates a clone of the classifier, trains that clone on the training folds, and makes predictions  on  the  test  fold.  Then  it  counts  the  number  of  correct  predictions  and outputs the ratio of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cc7aa27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9669\n",
      "0.91625\n",
      "0.96785\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits=3, random_state=42, shuffle=True)\n",
    "\n",
    "for train_index, test_index in skfolds.split(X_train, y_train_5):\n",
    "    clone_clf = clone(sgd_clf)\n",
    "    X_train_folds = X_train[train_index]\n",
    "    y_train_folds = y_train_5[train_index]\n",
    "    X_test_fold = X_train[test_index]\n",
    "    y_test_fold = y_train_5[test_index]\n",
    "    \n",
    "    clone_clf.fit(X_train_folds, y_train_folds)\n",
    "    y_pred = clone_clf.predict(X_test_fold)\n",
    "    n_correct = sum(y_pred == y_test_fold)\n",
    "    print(n_correct/len(y_pred)) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ece2fac",
   "metadata": {},
   "source": [
    "Let’s  use  the  *cross_val_score()* function  to  evaluate  our  *SGDClassifier*  model, using K-fold cross-validation with three folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "01a740a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95035, 0.96035, 0.9604 ])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60920a0c",
   "metadata": {},
   "source": [
    "Lets looka at a classifier that just classifies every single image in the \"not-5\" class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a0778213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd540ae",
   "metadata": {},
   "source": [
    "Let's find the model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0b2e5b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91125, 0.90855, 0.90915])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "never_5_clf = Never5Classifier()\n",
    "cross_val_score(never_5_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1e6ba3",
   "metadata": {},
   "source": [
    "That’s  right,  it  has  over  90%  accuracy!  This  is  simply  because  only  about  10%  of  the images are 5s, so if you always guess that an image is not a 5, you will be right about 90% of the time. Beats Nostradamus. This demonstrates why accuracy is generally not the preferred performance measurefor  classifiers,  especially  when  you  are  dealing  with  skewed  datasets  (i.e.,  when  someclasses are much more frequent than others)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('venv': venv)",
   "language": "python",
   "name": "python396jvsc74a57bd0c9b08adf87d7192cfe942781fd54415438870c456d89c858e0a76f55356c9d48"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
